{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chains summary saved to ./collected_chains_summary.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def collect_chains(base_path, label, chain_source):\n",
    "    \"\"\"\n",
    "    Collect all chains from a given directory and assign a label and source.\n",
    "    :param base_path: Path to the directory containing JSON files.\n",
    "    :param label: Valid or invalid chain type (e.g., \"valid\", \"invalid_type1\").\n",
    "    :param chain_source: Chain source (e.g., \"latest\" or \"influential\").\n",
    "    :return: A list of dictionaries containing chain metadata and content.\n",
    "    \"\"\"\n",
    "    chains = []\n",
    "    for root, _, files in os.walk(base_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".json\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, \"r\") as f:\n",
    "                    content = json.load(f)\n",
    "                chains.append({\n",
    "                    \"file_name\": file,\n",
    "                    \"chain_label\": label,\n",
    "                    \"chain_source\": chain_source,\n",
    "                    \"file_path\": file_path,\n",
    "                    \"content\": content\n",
    "                })\n",
    "    return chains\n",
    "\n",
    "# Define all paths with updated chain sources\n",
    "data_paths = [\n",
    "    {\"path\": \"../ground_truth_path/result_chains\", \"label\": \"valid\", \"source\": \"latest\"},\n",
    "    {\"path\": \"../ground_truth_path/invalid_chains_type1\", \"label\": \"invalid_type1\", \"source\": \"latest\"},\n",
    "    {\"path\": \"../ground_truth_path/invalid_chains_type2\", \"label\": \"invalid_type2\", \"source\": \"latest\"},\n",
    "    {\"path\": \"../ground_truth_path_fred/result_chains\", \"label\": \"valid\", \"source\": \"influential\"},\n",
    "    {\"path\": \"../ground_truth_path_fred/invalid_chains_type1\", \"label\": \"invalid_type1\", \"source\": \"influential\"},\n",
    "    {\"path\": \"../ground_truth_path_fred/invalid_chains_type2\", \"label\": \"invalid_type2\", \"source\": \"influential\"},\n",
    "]\n",
    "\n",
    "# Collect all chains\n",
    "all_chains = []\n",
    "for data_path in data_paths:\n",
    "    chains = collect_chains(data_path[\"path\"], data_path[\"label\"], data_path[\"source\"])\n",
    "    all_chains.extend(chains)\n",
    "\n",
    "# Save the collected data as a JSON object\n",
    "output_path = \"./collected_chains_summary.json\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(all_chains, f, indent=4)\n",
    "\n",
    "print(f\"Chains summary saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Collected Data Summary ###\n",
      "Total Chains: 2018\n",
      "Chains Ending in 2023 or 2024 by Label: {'valid': 201, 'invalid_type1': 814, 'invalid_type2': 269}\n",
      "Total Chains Ending in 2023 or 2024: 1284\n",
      "Chain Labels Distribution: {'valid': 379, 'invalid_type1': 1184, 'invalid_type2': 455}\n",
      "Chain Sources Distribution: {'latest': 927, 'influential': 1091}\n",
      "Unique Review IDs: 198\n",
      "Average Content Length: 11.29\n",
      "\n",
      "Top 5 Review IDs by Chain Count:\n",
      "  CD001461: 27 chains\n",
      "  CD002800: 25 chains\n",
      "  CD000951: 21 chains\n",
      "  CD006000: 21 chains\n",
      "  CD002048: 20 chains\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Load the collected chains summary\n",
    "input_path = \"./collected_chains_summary.json\"\n",
    "with open(input_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Initialize counters and containers for statistics\n",
    "total_chains = len(data)\n",
    "chain_labels = Counter()\n",
    "chain_sources = Counter()\n",
    "review_id_counts = Counter()\n",
    "content_lengths = []\n",
    "chains_ending_2023_2024 = Counter()  # Tracks chains ending in 2023/2024 by chain_label\n",
    "\n",
    "# Extract statistics\n",
    "for chain in data:\n",
    "    chain_labels[chain[\"chain_label\"]] += 1\n",
    "    chain_sources[chain[\"chain_source\"]] += 1\n",
    "    \n",
    "    # Extract review_id from file_name (e.g., \"CD000017\")\n",
    "    review_id = chain[\"file_name\"].split(\"_\")[2]\n",
    "    review_id_counts[review_id] += 1\n",
    "    \n",
    "    # Calculate content length\n",
    "    content_length = len(chain[\"content\"])\n",
    "    content_lengths.append(content_length)\n",
    "    \n",
    "    # Check if chain ends in 2023 or 2024\n",
    "    last_paper = chain[\"content\"][-1] if chain[\"content\"] else None\n",
    "    if last_paper and isinstance(last_paper, dict):\n",
    "        year = last_paper.get(\"year\")  # Adjust key based on your data\n",
    "        if year in {2023, 2024}:\n",
    "            chains_ending_2023_2024[chain[\"chain_label\"]] += 1\n",
    "\n",
    "# Compute additional stats\n",
    "unique_review_ids = len(review_id_counts)\n",
    "avg_content_length = sum(content_lengths) / total_chains if total_chains > 0 else 0\n",
    "total_chains_ending_2023_2024 = sum(chains_ending_2023_2024.values())\n",
    "\n",
    "# Display the statistics\n",
    "print(\"### Collected Data Summary ###\")\n",
    "print(f\"Total Chains: {total_chains}\")\n",
    "print(f\"Chains Ending in 2023 or 2024 by Label: {dict(chains_ending_2023_2024)}\")\n",
    "print(f\"Total Chains Ending in 2023 or 2024: {total_chains_ending_2023_2024}\")\n",
    "print(f\"Chain Labels Distribution: {dict(chain_labels)}\")\n",
    "print(f\"Chain Sources Distribution: {dict(chain_sources)}\")\n",
    "print(f\"Unique Review IDs: {unique_review_ids}\")\n",
    "print(f\"Average Content Length: {avg_content_length:.2f}\")\n",
    "print(\"\\nTop 5 Review IDs by Chain Count:\")\n",
    "for review_id, count in review_id_counts.most_common(5):\n",
    "    print(f\"  {review_id}: {count} chains\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Statistics for Train ###\n",
      "Total Chains: 1364\n",
      "Chain Labels Distribution: {'valid': 259, 'invalid_type1': 793, 'invalid_type2': 312}\n",
      "Chain Sources Distribution: {'latest': 634, 'influential': 730}\n",
      "Unique Review IDs: 138\n",
      "Chains Ending in 2023 or 2024: 850\n",
      "Average Chain Length: 11.23\n",
      "Chain Length by Type:\n",
      "  valid: Min=2, Max=27, Avg=8.95\n",
      "  invalid_type1: Min=3, Max=27, Avg=12.46\n",
      "  invalid_type2: Min=2, Max=25, Avg=9.98\n",
      "\n",
      "### Statistics for Validation ###\n",
      "Total Chains: 326\n",
      "Chain Labels Distribution: {'valid': 52, 'invalid_type1': 203, 'invalid_type2': 71}\n",
      "Chain Sources Distribution: {'latest': 133, 'influential': 193}\n",
      "Unique Review IDs: 29\n",
      "Chains Ending in 2023 or 2024: 240\n",
      "Average Chain Length: 12.03\n",
      "Chain Length by Type:\n",
      "  valid: Min=2, Max=20, Avg=10.63\n",
      "  invalid_type1: Min=3, Max=20, Avg=12.87\n",
      "  invalid_type2: Min=4, Max=28, Avg=10.65\n",
      "\n",
      "### Statistics for Test ###\n",
      "Total Chains: 320\n",
      "Chain Labels Distribution: {'valid': 60, 'invalid_type1': 188, 'invalid_type2': 72}\n",
      "Chain Sources Distribution: {'latest': 152, 'influential': 168}\n",
      "Unique Review IDs: 31\n",
      "Chains Ending in 2023 or 2024: 194\n",
      "Average Chain Length: 11.06\n",
      "Chain Length by Type:\n",
      "  valid: Min=2, Max=20, Avg=9.13\n",
      "  invalid_type1: Min=4, Max=20, Avg=12.37\n",
      "  invalid_type2: Min=2, Max=21, Avg=9.26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "def extract_review_id(file_name):\n",
    "    \"\"\"\n",
    "    Extract the review_id from the file name.\n",
    "    Assumes the file name has the format 'temporal_chain_<REVIEW_ID>_...'\n",
    "    \"\"\"\n",
    "    return file_name.split(\"_\")[2]  # Adjust index based on your naming convention\n",
    "\n",
    "def filter_short_chains(data):\n",
    "    \"\"\"\n",
    "    Filter out chains with a length of 1.\n",
    "    :param data: List of chains (e.g., JSON list).\n",
    "    :return: Filtered list of chains.\n",
    "    \"\"\"\n",
    "    return [chain for chain in data if len(chain[\"content\"]) > 1]\n",
    "\n",
    "def stratified_split(data, train_ratio=0.7, valid_ratio=0.15, test_ratio=0.15, seed=4321):\n",
    "    \"\"\"\n",
    "    Stratified and balanced split of chains into train, validation, and test sets,\n",
    "    ensuring that chains with the same review_id do not appear in multiple splits.\n",
    "    :param data: List of data items (e.g., JSON list).\n",
    "    :param train_ratio: Proportion of data to use for training.\n",
    "    :param valid_ratio: Proportion of data to use for validation.\n",
    "    :param test_ratio: Proportion of data to use for testing.\n",
    "    :param seed: Random seed for reproducibility.\n",
    "    :return: train, validation, and test splits.\n",
    "    \"\"\"\n",
    "    # Group data by review_id\n",
    "    review_groups = defaultdict(list)\n",
    "    for chain in data:\n",
    "        review_id = extract_review_id(chain[\"file_name\"])\n",
    "        review_groups[review_id].append(chain)\n",
    "    \n",
    "    # Further group by chain_label\n",
    "    label_groups = defaultdict(list)\n",
    "    for review_id, chains in review_groups.items():\n",
    "        chain_label = chains[0][\"chain_label\"]  # Assume all chains under a review_id have the same label\n",
    "        label_groups[chain_label].append((review_id, chains))\n",
    "    \n",
    "    # Shuffle each label group\n",
    "    random.seed(seed)\n",
    "    for label in label_groups:\n",
    "        random.shuffle(label_groups[label])\n",
    "    \n",
    "    # Create splits\n",
    "    train, valid, test = [], [], []\n",
    "    for label, review_data in label_groups.items():\n",
    "        total = len(review_data)\n",
    "        train_size = int(total * train_ratio)\n",
    "        valid_size = int(total * valid_ratio)\n",
    "        \n",
    "        train_groups = review_data[:train_size]\n",
    "        valid_groups = review_data[train_size:train_size + valid_size]\n",
    "        test_groups = review_data[train_size + valid_size:]\n",
    "        \n",
    "        # Flatten the groups back into lists\n",
    "        train.extend([chain for _, chains in train_groups for chain in chains])\n",
    "        valid.extend([chain for _, chains in valid_groups for chain in chains])\n",
    "        test.extend([chain for _, chains in test_groups for chain in chains])\n",
    "    \n",
    "    return train, valid, test\n",
    "\n",
    "def calculate_statistics(split_data, split_name):\n",
    "    \"\"\"\n",
    "    Calculate and print statistics for a given split, including chains ending in 2023 or 2024\n",
    "    and chain length stats.\n",
    "    :param split_data: The data of the split.\n",
    "    :param split_name: Name of the split (e.g., \"train\").\n",
    "    \"\"\"\n",
    "    total_chains = len(split_data)\n",
    "    chain_labels = Counter(chain[\"chain_label\"] for chain in split_data)\n",
    "    chain_sources = Counter(chain[\"chain_source\"] for chain in split_data)\n",
    "    review_ids = {extract_review_id(chain[\"file_name\"]) for chain in split_data}\n",
    "    unique_review_ids = len(review_ids)\n",
    "    \n",
    "    # Chains ending in 2023 or 2024\n",
    "    chains_ending_2023_2024 = sum(\n",
    "        1 for chain in split_data\n",
    "        if chain[\"content\"] and isinstance(chain[\"content\"][-1], dict) and chain[\"content\"][-1].get(\"year\") in {2023, 2024}\n",
    "    )\n",
    "    \n",
    "    # Chain length stats\n",
    "    chain_lengths = [len(chain[\"content\"]) for chain in split_data if chain[\"content\"]]\n",
    "    avg_chain_length = sum(chain_lengths) / len(chain_lengths) if chain_lengths else 0\n",
    "    \n",
    "    # Chain length by type\n",
    "    chain_length_by_label = defaultdict(list)\n",
    "    for chain in split_data:\n",
    "        if chain[\"content\"]:\n",
    "            chain_length_by_label[chain[\"chain_label\"]].append(len(chain[\"content\"]))\n",
    "    \n",
    "    print(f\"### Statistics for {split_name} ###\")\n",
    "    print(f\"Total Chains: {total_chains}\")\n",
    "    print(f\"Chain Labels Distribution: {dict(chain_labels)}\")\n",
    "    print(f\"Chain Sources Distribution: {dict(chain_sources)}\")\n",
    "    print(f\"Unique Review IDs: {unique_review_ids}\")\n",
    "    print(f\"Chains Ending in 2023 or 2024: {chains_ending_2023_2024}\")\n",
    "    print(f\"Average Chain Length: {avg_chain_length:.2f}\")\n",
    "    print(\"Chain Length by Type:\")\n",
    "    for label, lengths in chain_length_by_label.items():\n",
    "        print(f\"  {label}: Min={min(lengths)}, Max={max(lengths)}, Avg={sum(lengths)/len(lengths):.2f}\")\n",
    "    print(\"\")\n",
    "\n",
    "# Load the collected chains summary\n",
    "input_path = \"./collected_chains_summary.json\"\n",
    "with open(input_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "data = filter_short_chains(data)\n",
    "\n",
    "# Perform stratified split\n",
    "train_data, valid_data, test_data = stratified_split(data)\n",
    "\n",
    "# Calculate and display statistics\n",
    "calculate_statistics(train_data, \"Train\")\n",
    "calculate_statistics(valid_data, \"Validation\")\n",
    "calculate_statistics(test_data, \"Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Statistics for Balanced Dataset with 50-50 Valid and Invalid Chains ###\n",
      "Total Chains: 3523\n",
      "Chain Labels Distribution: {'valid': 1884, 'invalid_type1': 1184, 'invalid_type2': 455}\n",
      "Chain Sources Distribution: {'latest': 1772, 'influential': 1751}\n",
      "Chains Ending in 2023 or 2024: 1482\n",
      "Average Chain Length: 8.61\n",
      "Chain Length by Type:\n",
      "  valid: Min=2, Max=27, Avg=5.83\n",
      "  invalid_type1: Min=3, Max=27, Avg=12.52\n",
      "  invalid_type2: Min=2, Max=28, Avg=9.97\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def calculate_statistics(data, dataset_name=\"Dataset\"):\n",
    "    \"\"\"\n",
    "    Calculate and display statistics for a dataset.\n",
    "    :param data: List of chains.\n",
    "    :param dataset_name: Name of the dataset (e.g., \"Updated Dataset\").\n",
    "    \"\"\"\n",
    "    total_chains = len(data)\n",
    "    chain_labels = Counter(chain[\"chain_label\"] for chain in data)\n",
    "    chain_sources = Counter(chain[\"chain_source\"] for chain in data)\n",
    "    chain_lengths = [len(chain[\"content\"]) for chain in data]\n",
    "    avg_chain_length = sum(chain_lengths) / len(chain_lengths) if chain_lengths else 0\n",
    "\n",
    "    # Chains Ending in 2023 or 2024\n",
    "    chains_ending_2023_2024 = sum(\n",
    "        1 for chain in data\n",
    "        if chain[\"content\"] and isinstance(chain[\"content\"][-1], dict) and chain[\"content\"][-1].get(\"year\") in {2023, 2024}\n",
    "    )\n",
    "\n",
    "    # Chain Length by Type\n",
    "    chain_length_by_label = defaultdict(list)\n",
    "    for chain in data:\n",
    "        chain_length_by_label[chain[\"chain_label\"]].append(len(chain[\"content\"]))\n",
    "\n",
    "    print(f\"### Statistics for {dataset_name} ###\")\n",
    "    print(f\"Total Chains: {total_chains}\")\n",
    "    print(f\"Chain Labels Distribution: {dict(chain_labels)}\")\n",
    "    print(f\"Chain Sources Distribution: {dict(chain_sources)}\")\n",
    "    print(f\"Chains Ending in 2023 or 2024: {chains_ending_2023_2024}\")\n",
    "    print(f\"Average Chain Length: {avg_chain_length:.2f}\")\n",
    "    print(\"Chain Length by Type:\")\n",
    "    for label, lengths in chain_length_by_label.items():\n",
    "        print(f\"  {label}: Min={min(lengths)}, Max={max(lengths)}, Avg={sum(lengths)/len(lengths):.2f}\")\n",
    "    print(\"\")\n",
    "\n",
    "def balance_valid_and_invalid_chains(data, target_ratio=1.0, window_size=5, step_size=1, min_chain_length=3):\n",
    "    \"\"\"\n",
    "    Dynamically split valid chains and balance them with invalid chains until the desired ratio is achieved.\n",
    "    Marks split chains with a flag for distinction.\n",
    "    :param data: List of chains.\n",
    "    :param target_ratio: Desired ratio of valid to negative chains.\n",
    "    :param window_size: Maximum length of each subchain.\n",
    "    :param step_size: Step size for overlapping subchains.\n",
    "    :param min_chain_length: Minimum chain length to include in splitting.\n",
    "    :return: Updated dataset with balanced valid and negative chains.\n",
    "    \"\"\"\n",
    "    updated_data = []\n",
    "    valid_chains = []\n",
    "    negative_count = sum(1 for chain in data if chain[\"chain_label\"] in {\"invalid_type1\", \"invalid_type2\"})\n",
    "    valid_count = 0\n",
    "\n",
    "    for chain in data:\n",
    "        if chain[\"chain_label\"] == \"valid\" and len(chain[\"content\"]) >= min_chain_length:\n",
    "            # Mark original valid chain\n",
    "            chain[\"generated_from_split\"] = False\n",
    "            valid_chains.append(chain)\n",
    "            valid_count += 1\n",
    "\n",
    "            # Generate overlapping subchains\n",
    "            content = chain[\"content\"]\n",
    "            for start_idx in range(0, len(content) - window_size + 1, step_size):\n",
    "                subchain_content = content[start_idx : start_idx + window_size]\n",
    "                subchain = {\n",
    "                    \"file_name\": f\"{chain['file_name']}_split_{start_idx}\",\n",
    "                    \"chain_label\": chain[\"chain_label\"],\n",
    "                    \"chain_source\": chain[\"chain_source\"],\n",
    "                    \"file_path\": chain[\"file_path\"],  # Keep original path for reference\n",
    "                    \"content\": subchain_content,\n",
    "                    \"generated_from_split\": True,  # Mark as split\n",
    "                }\n",
    "                valid_chains.append(subchain)\n",
    "                valid_count += 1\n",
    "\n",
    "                # Stop splitting if valid chains exceed the target ratio\n",
    "                if valid_count >= target_ratio * negative_count:\n",
    "                    break\n",
    "        else:\n",
    "            # Keep the chain as is\n",
    "            chain[\"generated_from_split\"] = False  # Negative chains are not split\n",
    "            updated_data.append(chain)\n",
    "\n",
    "    # Combine valid and negative chains\n",
    "    updated_data.extend(valid_chains)\n",
    "    return updated_data\n",
    "\n",
    "\n",
    "# Load the original dataset\n",
    "input_path = \"./collected_chains_summary.json\"\n",
    "with open(input_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "data = filter_short_chains(data)\n",
    "\n",
    "# Adjusted function for balancing chains\n",
    "data_with_balanced_valids = balance_valid_and_invalid_chains(\n",
    "    data, target_ratio=1.0, window_size=5, step_size=1, min_chain_length=5\n",
    ")\n",
    "\n",
    "# Calculate and display statistics for the updated dataset\n",
    "calculate_statistics(data_with_balanced_valids, \"Balanced Dataset with 50-50 Valid and Invalid Chains\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced dataset saved to ./balanced_chains_50_50.json.\n"
     ]
    }
   ],
   "source": [
    "# Save the updated dataset\n",
    "output_path = \"./balanced_chains_50_50.json\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(data_with_balanced_valids, f, indent=4)\n",
    "\n",
    "print(f\"Balanced dataset saved to {output_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Statistics for Train ###\n",
      "Total Chains: 2490\n",
      "Chain Labels Distribution: {'valid': 1331, 'invalid_type1': 834, 'invalid_type2': 325}\n",
      "Chain Sources Distribution: {'latest': 1199, 'influential': 1291}\n",
      "Chains Ending in 2023 or 2024: 1047\n",
      "Average Chain Length: 8.65\n",
      "Chain Length by Type:\n",
      "  valid: Min=2, Max=27, Avg=5.84\n",
      "  invalid_type1: Min=3, Max=27, Avg=12.62\n",
      "  invalid_type2: Min=2, Max=28, Avg=9.98\n",
      "\n",
      "### Statistics for Validation ###\n",
      "Total Chains: 523\n",
      "Chain Labels Distribution: {'valid': 296, 'invalid_type1': 165, 'invalid_type2': 62}\n",
      "Chain Sources Distribution: {'latest': 276, 'influential': 247}\n",
      "Chains Ending in 2023 or 2024: 215\n",
      "Average Chain Length: 8.07\n",
      "Chain Length by Type:\n",
      "  valid: Min=2, Max=21, Avg=5.71\n",
      "  invalid_type1: Min=3, Max=21, Avg=11.94\n",
      "  invalid_type2: Min=2, Max=21, Avg=9.02\n",
      "\n",
      "### Statistics for Test ###\n",
      "Total Chains: 510\n",
      "Chain Labels Distribution: {'valid': 257, 'invalid_type1': 185, 'invalid_type2': 68}\n",
      "Chain Sources Distribution: {'latest': 297, 'influential': 213}\n",
      "Chains Ending in 2023 or 2024: 220\n",
      "Average Chain Length: 8.99\n",
      "Chain Length by Type:\n",
      "  valid: Min=2, Max=18, Avg=5.92\n",
      "  invalid_type1: Min=3, Max=18, Avg=12.57\n",
      "  invalid_type2: Min=4, Max=21, Avg=10.82\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the balanced dataset\n",
    "input_path = \"./balanced_chains_50_50.json\"\n",
    "with open(input_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Filter out short chains (length <= 1)\n",
    "data = filter_short_chains(data)\n",
    "\n",
    "# Perform stratified split\n",
    "train_data, valid_data, test_data = stratified_split(data, train_ratio=0.7, valid_ratio=0.15, test_ratio=0.15)\n",
    "\n",
    "# Calculate and display statistics for each split\n",
    "calculate_statistics(train_data, \"Train\")\n",
    "calculate_statistics(valid_data, \"Validation\")\n",
    "calculate_statistics(test_data, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced splits saved to ./balanced_splits/.\n"
     ]
    }
   ],
   "source": [
    "# Save the splits\n",
    "output_dir = \"./balanced_splits/\"\n",
    "import os\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "with open(f\"{output_dir}/train.json\", \"w\") as f:\n",
    "    json.dump(train_data, f, indent=4)\n",
    "\n",
    "with open(f\"{output_dir}/valid.json\", \"w\") as f:\n",
    "    json.dump(valid_data, f, indent=4)\n",
    "\n",
    "with open(f\"{output_dir}/test.json\", \"w\") as f:\n",
    "    json.dump(test_data, f, indent=4)\n",
    "\n",
    "print(f\"Balanced splits saved to {output_dir}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### alpaca format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "def format_reasoning_chain(content):\n",
    "    \"\"\"\n",
    "    Formats the reasoning chain as a numbered list with paper title and abstract.\n",
    "    \"\"\"\n",
    "    formatted_chain = []\n",
    "    for i, paper in enumerate(content, start=1):\n",
    "        title = paper.get(\"title\", \"No Title Provided\")\n",
    "        abstract = paper.get(\"abstract\", \"No Abstract Provided\")\n",
    "        formatted_chain.append(f\"{i}. PAPER TITLE: {title}\\n   ABSTRACT: {abstract}\")\n",
    "    return \"\\n\".join(formatted_chain)\n",
    "\n",
    "\n",
    "def convert_to_alpaca_format(entry):\n",
    "    \"\"\"\n",
    "    Converts a dataset entry into Alpaca format with 'instruction', 'input', and 'output'.\n",
    "    \"\"\"\n",
    "    label = \"invalid\" if entry[\"chain_label\"] in {\"invalid_type1\", \"invalid_type2\"} else entry[\"chain_label\"]\n",
    "    formatted_chain = format_reasoning_chain(entry[\"content\"])  # Format reasoning chain\n",
    "\n",
    "    return {\n",
    "        \"instruction\": f\"Hypotheses are frequently the starting point when undertaking the empirical portion of the scientific process. They guide the types of data collected, analyses conducted, and inferences drawn. You are a scientist. Your task is to evaluate the relevance of a reasoning chain derived from a series of related papers. Each paper in the chain builds on the previous one, starting from a source paper and ending with a final paper. A reasoning chain is considered 'valid' if the logical connections between all the papers in the chain are coherent, and the final hypothesis logically inspired from or depends on the source paper, either directly or through intermediate papers. A reasoning chain is 'invalid' if any logical break exists in the chain, such as unrelated intermediate papers, or  if the final hypothesis does not logically depend on the previous papers. Your task is to classify the given reasoning chain as either 'valid' or 'invalid'. Your evaluation should be based on the logical relevance and progression between the papers.  Answer should be only 'valid' or 'invalid'.\",\n",
    "        \"input\": f\"Reasoning Chain:\\n{formatted_chain}\",\n",
    "        \"output\": label,  # Expected answer ('valid' or 'invalid')\n",
    "    }\n",
    "    # sometimes you will be given the target hypothesis - add this to the prompt\n",
    "    # 1. extract target hypothesis\n",
    "    # 2. 50 percent of data with conditioned on hypothesis and fine tune the model\n",
    "    # 3. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chains with length above 25:\n",
      "Train: 14\n",
      "Valid: 0\n",
      "Test: 0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def remove_2024_papers(data):\n",
    "    \"\"\"\n",
    "    Removes papers published in 2024 from the reasoning chains in the dataset.\n",
    "    :param data: List of chains (each chain is a dictionary with a 'content' field).\n",
    "    :return: Updated dataset with 2024 papers removed from the chains.\n",
    "    \"\"\"\n",
    "    updated_data = []\n",
    "    for chain in data:\n",
    "        # Filter out entries in the content field with year == 2024\n",
    "        chain[\"content\"] = [paper for paper in chain[\"content\"] if paper.get(\"year\") != 2024]\n",
    "        \n",
    "        # Add the chain to the updated dataset only if it still contains papers\n",
    "        if chain[\"content\"]:\n",
    "            updated_data.append(chain)\n",
    "    return updated_data\n",
    "\n",
    "\n",
    "# Load split datasets\n",
    "with open(\"./balanced_splits/train.json\", \"r\") as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "with open(\"./balanced_splits/valid.json\", \"r\") as f:\n",
    "    valid_data = json.load(f)\n",
    "\n",
    "with open(\"./balanced_splits/test.json\", \"r\") as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "# Remove 2024 papers from each split\n",
    "train_data = remove_2024_papers(train_data)\n",
    "valid_data = remove_2024_papers(valid_data)\n",
    "test_data = remove_2024_papers(test_data)\n",
    "\n",
    "def count_long_chains(data, length_threshold=25):\n",
    "    \"\"\"\n",
    "    Counts the number of chains with a length above the specified threshold.\n",
    "    :param data: List of chains (each chain is a dictionary with a 'content' field).\n",
    "    :param length_threshold: Minimum length to qualify as a \"long chain.\"\n",
    "    :return: Count of chains with a length above the threshold.\n",
    "    \"\"\"\n",
    "    return sum(1 for chain in data if len(chain[\"content\"]) > length_threshold)\n",
    "\n",
    "# Count long chains in each dataset\n",
    "train_long_chains = count_long_chains(train_data)\n",
    "valid_long_chains = count_long_chains(valid_data)\n",
    "test_long_chains = count_long_chains(test_data)\n",
    "\n",
    "print(f\"Number of chains with length above 25:\")\n",
    "print(f\"Train: {train_long_chains}\")\n",
    "print(f\"Valid: {valid_long_chains}\")\n",
    "print(f\"Test: {test_long_chains}\")\n",
    "\n",
    "def remove_long_chains(data, length_threshold=25):\n",
    "    \"\"\"\n",
    "    Removes chains with a length above the specified threshold from the dataset.\n",
    "    :param data: List of chains (each chain is a dictionary with a 'content' field).\n",
    "    :param length_threshold: Maximum allowed length for a chain to be included.\n",
    "    :return: Updated dataset with long chains removed.\n",
    "    \"\"\"\n",
    "    return [chain for chain in data if len(chain[\"content\"]) <= length_threshold]\n",
    "\n",
    "# Remove long chains from the train dataset\n",
    "#train_data = remove_long_chains(train_data)\n",
    "\n",
    "# Convert split datasets into Hugging Face datasets\n",
    "train_dataset = Dataset.from_list(train_data)\n",
    "valid_dataset = Dataset.from_list(valid_data)\n",
    "test_dataset = Dataset.from_list(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b8ab8a822d48169f5fcfb9bfdb21c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2490 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d80a3582587443eb086ac173a4aa415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/523 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5d304b1071e48c5835557958967d56d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/510 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply the conversion to Alpaca format\n",
    "alpaca_train_dataset = train_dataset.map(\n",
    "    lambda x: convert_to_alpaca_format(x),\n",
    "    remove_columns=train_dataset.column_names\n",
    ")\n",
    "\n",
    "alpaca_valid_dataset = valid_dataset.map(\n",
    "    lambda x: convert_to_alpaca_format(x),\n",
    "    remove_columns=valid_dataset.column_names\n",
    ")\n",
    "\n",
    "alpaca_test_dataset = test_dataset.map(\n",
    "    lambda x: convert_to_alpaca_format(x),\n",
    "    remove_columns=test_dataset.column_names\n",
    ")\n",
    "\n",
    "# Combine into a DatasetDict\n",
    "alpaca_dataset = DatasetDict({\n",
    "    \"train\": alpaca_train_dataset,\n",
    "    \"valid\": alpaca_valid_dataset,\n",
    "    \"test\": alpaca_test_dataset,\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a426cb6c644e56a7344bf1316f9524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e55566e32cd44249719001ce9d87157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec89940260d64acb9d0c1a74e132e44e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpaca datasets saved to ./alpaca_formatted_splits/\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"./alpaca_formatted_splits/\"\n",
    "import os\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "alpaca_dataset[\"train\"].to_json(f\"{output_dir}/alpaca_train.jsonl\")\n",
    "alpaca_dataset[\"valid\"].to_json(f\"{output_dir}/alpaca_valid.jsonl\")\n",
    "alpaca_dataset[\"test\"].to_json(f\"{output_dir}/alpaca_test.jsonl\")\n",
    "\n",
    "print(f\"Alpaca datasets saved to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### alapca input to mistralLite format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfff8ce3bb8448538ef929b3e32252d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MistralLite train dataset saved to ./mistral_format_multi_task3/mistral_train.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93841ff619c446984e98322f82af233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating valid split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MistralLite valid dataset saved to ./mistral_format_multi_task3/mistral_valid.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a74e847f99bc4a4a87047a87ab949c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MistralLite test dataset saved to ./mistral_format_multi_task3/mistral_test.jsonl\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Input and output directories\n",
    "input_dir = \"./alpaca_multi_task3/\"\n",
    "output_dir = \"./mistral_format_multi_task3/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def convert_to_mistral_format(entry):\n",
    "    \"\"\"\n",
    "    Converts an Alpaca-formatted entry to the MistralLite format.\n",
    "    \"\"\"\n",
    "    instruction = entry[\"instruction\"]\n",
    "    input_text = entry[\"input\"]\n",
    "    output_text = entry[\"output\"]\n",
    "\n",
    "    # Create the MistralLite prompt format\n",
    "    if input_text.strip():\n",
    "        prompt = f\"<|prompter|>{instruction}\\n{input_text}</s><|assistant|>{output_text}\"\n",
    "    else:\n",
    "        prompt = f\"<|prompter|>{instruction}</s><|assistant|>{output_text}\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "# Process and save datasets\n",
    "splits = [\"train\", \"valid\", \"test\"]\n",
    "for split in splits:\n",
    "    # Load the dataset\n",
    "    alpaca_dataset = load_dataset(\"json\", data_files={split: f\"{input_dir}/alpaca_{split}.jsonl\"})\n",
    "    \n",
    "    mistral_data = []\n",
    "    for entry in alpaca_dataset[split]:\n",
    "        mistral_entry = convert_to_mistral_format(entry)\n",
    "        mistral_data.append(mistral_entry)\n",
    "\n",
    "    # Save to new directory in MistralLite format\n",
    "    mistral_output_file = os.path.join(output_dir, f\"mistral_{split}.jsonl\")\n",
    "    with open(mistral_output_file, \"w\") as f:\n",
    "        for mistral_entry in mistral_data:\n",
    "            json_line = json.dumps({\"text\": mistral_entry})  # Wrap each line in a JSON object\n",
    "            f.write(json_line + \"\\n\")  # Write each JSON object as a new line\n",
    "\n",
    "\n",
    "    print(f\"MistralLite {split} dataset saved to {mistral_output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scigen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
